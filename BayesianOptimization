#Bayesian Optimization for GBM
bounds = {
    'max_depth':(5,20),
    'ntrees': (50,500),
    'min_rows':(10,35),
    'learn_rate':(0.001, 0.2),
    'sample_rate':(0.5,0.9),
    'col_sample_rate':(0.2,0.8)
}

def train_model(max_depth, 
                ntrees,
                min_rows, 
                learn_rate, 
                sample_rate, 
                col_sample_rate):
    params = {
        'max_depth': int(max_depth),
        'ntrees': int(ntrees),
        'min_rows': int(min_rows),
        'learn_rate':learn_rate,
        'sample_rate':sample_rate,
        'col_sample_rate':col_sample_rate
    }
    
    model = H2OGradientBoostingEstimator(seed=1, nfolds=5,**params)
    model.train(x=selected_features, y=var_target, training_frame=train_hdf, validation_frame=valid_hdf)
    return -model.mse()

optimizer = BayesianOptimization(
    f=train_model,
    pbounds=bounds,
    random_state=1,
)
optimizer.maximize(init_points=10, n_iter=100)


dict_tmp1={}
dict_tmp2={}
for i, res in enumerate(optimizer.res):
    dict_tmp1[i] = {'iteration': int(i), 'mae': res['target']}
    dict_tmp2[i] = res['params']
df_optimizer = pd.DataFrame(dict_tmp1).transpose().merge(pd.DataFrame(dict_tmp2).transpose(), left_index=True, right_index=True)
df_optimizer
